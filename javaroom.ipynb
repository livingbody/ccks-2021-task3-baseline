{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、“英特尔创新大师杯”深度学习挑战赛 赛道3：CCKS2021中文NLP地址相关性任务\n",
    "\n",
    "赛题地址： [https://tianchi.aliyun.com/competition/entrance/531901/information](https://tianchi.aliyun.com/competition/entrance/531901/information)\n",
    "\n",
    "## 1.赛题背景\n",
    "地址文本相关性任务在现实世界中存在着广泛的应用场景，如：基于地理信息搜索的地理位置服务、对于突发事件位置信息的快速搜索定位、不同地址信息系统的对齐等等。\n",
    "\n",
    "日常生活中输入的地址文本可以为以下几种形式：\n",
    "\n",
    "* 包含四级行政区划及路名路号POI的规范地址文本；\n",
    "* 地址要素缺省的规范地址文本，例：只有路名+路号、只有POI；\n",
    "* 非规范的地址文本、口语化的地址信息描述，例：阿里西溪园区东门旁亲橙里；\n",
    "* 地址文本相关性主要是衡量地址间的相似程度，地址要素解析与地址相关性共同构成了中文地址处理两大核心任务，具有很大的商业价值。目前中文地址领域缺少标准的评测和数据集，这次我们将开放较大规模的标注语料，希望和社区共同推动地址文本处理领域的发展。\n",
    "\n",
    "## 2.赛题描述\n",
    "本评测任务为基于地址文本的相关性任务。即对于给定的一个地址query以及若干个候选地址文本，参赛系统需要对query与候选地址文本的匹配程度进行打分。\n",
    "\n",
    "多样化的地址文本写法对地址文本的相关性任务提出的挑战如下：\n",
    "\n",
    "* 同一个地址存在多种写法，没有给定的改写词表；\n",
    "* 地址query一般存在省市区等限制条件，需要结合限制条件分析相关性；\n",
    "* 不同地市地址规范不一，对模型泛化性提出更高要求；\n",
    "## 3.数据说明\n",
    "输入：输入文件包含若干个query-地址文本对\n",
    "\n",
    "输出：输出文本每一行包括此query-地址文本对的匹配程度，分为完全匹配、部分匹配、不匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二、数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.paddlenlp更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.2.0)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.5)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.数据解压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !unzip 'data/data95669/“英特尔创新大师杯”深度学习挑战赛 赛道3：CCKS2021中文NLP地址相关性任务.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !mv 'б░╙в╠╪╢√┤┤╨┬┤є╩ж▒нб▒╔ю╢╚╤з╧░╠Ї╒╜╚№ ╚№╡└3г║CCKS2021╓╨╬─NLP╡╪╓╖╧р╣╪╨╘╚╬╬ё' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !mv 'dataset/╕ё╩╜╫╘▓щ╜┼▒╛.py' check.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text_id\": \"e225b9fd36b8914f42c188fc92e8918f\", \"query\": \"河南省巩义市新华路街道办事处桐和街6号钢苑新区3号楼一单元\", \"candidate\": [{\"text\": \"巩义市桐和街\", \"label\": \"不匹配\"}, {\"text\": \"桐和街依家小店\", \"label\": \"不匹配\"}, {\"text\": \"桐和街CHANG六LIULIU\", \"label\": \"不匹配\"}, {\"text\": \"桐和街佳乐钢琴\", \"label\": \"不匹配\"}, {\"text\": \"世博领秀城南门桐和街囍饭食堂\", \"label\": \"不匹配\"}]}\r\n",
      "{\"text_id\": \"b2418ead7b48db4c09caa2934843c1b4\", \"query\": \"老垅坡高家组省建五公司\", \"candidate\": [{\"text\": \"高家巷省建五公司岳阳分公司\", \"label\": \"完全匹配\"}, {\"text\": \"建设北路346号省建5公司\", \"label\": \"不匹配\"}, {\"text\": \"老垅坡路西100米省建三公司(岳阳分公司)\", \"label\": \"不匹配\"}, {\"text\": \"寇庄西路101号省建五公司\", \"label\": \"不匹配\"}, {\"text\": \"卓刀泉南路21号省五建公司省建五公司\", \"label\": \"不匹配\"}]}\r\n",
      "{\"text_id\": \"5fa94565eb53463fa94ece56e8356fdc\", \"query\": \"西关人和路工商银行对过腾信医药一楼眼镜店\", \"candidate\": [{\"text\": \"河门口北街33号中国工商银行(河门口支行)\", \"label\": \"不匹配\"}, {\"text\": \"河门口北街33号中国工商银行ATM(河门口支行)\", \"label\": \"不匹配\"}, {\"text\": \"清香坪东街(食为天旁)中国工商银行24小时自助银行\", \"label\": \"不匹配\"}, {\"text\": \"陶家渡东路209号中国工商银行24小时自助银行(巴关河支行)\", \"label\": \"不匹配\"}, {\"text\": \"苏铁中路110号中国工商银行24小时自助银行(清香坪支行)\", \"label\": \"不匹配\"}]}\r\n",
      "{\"text_id\": \"10a2a7c833eea18f479a58f2d15a53b5\", \"query\": \"唐海县四农场场部王玉文\", \"candidate\": [{\"text\": \"场前路北50米曹妃甸区第四农场\", \"label\": \"部分匹配\"}, {\"text\": \"新区曹妃甸湿地曹妃湖东北侧曹妃甸慧钜文化创意产业园\", \"label\": \"不匹配\"}, {\"text\": \"建设大街255号四季华庭\", \"label\": \"不匹配\"}, {\"text\": \"曹妃甸区西环路\", \"label\": \"不匹配\"}, {\"text\": \"华兴路4附近曹妃歌厅(西门)\", \"label\": \"不匹配\"}]}\r\n",
      "{\"text_id\": \"7b82872ddc84f94733f5dac408d98bce\", \"query\": \"真北路818号近铁城市广场北座二楼\", \"candidate\": [{\"text\": \"真北路818号近铁城市广场北座\", \"label\": \"部分匹配\"}, {\"text\": \"真北路818号近铁城市广场北座(西南2门)\", \"label\": \"部分匹配\"}, {\"text\": \"真北路818号近铁城市广场北座(西南1门)\", \"label\": \"部分匹配\"}, {\"text\": \"真北路818号近铁城市广场北座2层捞王火锅\", \"label\": \"部分匹配\"}, {\"text\": \"金沙江路1685号118广场F1近铁城市广场北座(西北门)\", \"label\": \"部分匹配\"}]}\r\n",
      "{\"text_id\": \"24dbf73a46d68ef94bd69c8728adeed6\", \"query\": \"义亭工业区甘塘西路9号\", \"candidate\": [{\"text\": \"义亭镇甘塘西路9号秀颜化妆用具有限公司\", \"label\": \"部分匹配\"}, {\"text\": \"义亭镇甘塘西路9-1号义乌市恒凯玩具有限公司\", \"label\": \"部分匹配\"}, {\"text\": \"义乌市甘塘西路\", \"label\": \"不匹配\"}, {\"text\": \"黄金塘西路9号丹阳英福康电子科技有限公司\", \"label\": \"不匹配\"}, {\"text\": \"黄塘西路9号二楼卓悦国际舞蹈学院\", \"label\": \"不匹配\"}]}\r\n",
      "{\"text_id\": \"a48b64238490d0447bd5b39e527b280f\", \"query\": \"溧水县永阳镇东山大队谢岗村31号\", \"candidate\": [{\"text\": \"溧水区谢岗\", \"label\": \"不匹配\"}, {\"text\": \"溧水区东山\", \"label\": \"部分匹配\"}, {\"text\": \"永阳镇中山大队\", \"label\": \"不匹配\"}, {\"text\": \"溧水区东山线\", \"label\": \"不匹配\"}, {\"text\": \"东山线附近东山林业队\", \"label\": \"不匹配\"}]}\r\n",
      "{\"text_id\": \"adb0c58f99a60ae136daa5148fa188a7\", \"query\": \"纪家庙万兴家居D座二楼\", \"candidate\": [{\"text\": \"南三环西路玉泉营万兴家居D座2层德高防水\", \"label\": \"部分匹配\"}, {\"text\": \"玉泉营桥西万兴家居D座二层德国都芳漆\", \"label\": \"部分匹配\"}, {\"text\": \"花乡南三环玉泉营桥万兴家居D管4层羽翔红木\", \"label\": \"部分匹配\"}, {\"text\": \"花乡玉泉营桥西万兴家居D座3层69-71五洲装饰\", \"label\": \"部分匹配\"}, {\"text\": \"花乡乡南三环西路78号万兴国际家居广场纪家庙地区万兴家居广场\", \"label\": \"部分匹配\"}]}\r\n",
      "{\"text_id\": \"78f05d3265d15acde1e98cda41cf4f12\", \"query\": \"江苏省南京市江宁区禄口街道欢墩山\", \"candidate\": [{\"text\": \"江宁区欢墩山\", \"label\": \"部分匹配\"}]}\r\n",
      "{\"text_id\": \"9601ec765ee5a860992ec83b5743fe42\", \"query\": \"博美二期大门对面莲花新区7号地\", \"candidate\": [{\"text\": \"围场满族蒙古族自治县七号地\", \"label\": \"不匹配\"}, {\"text\": \"金梧桐宾馆东侧100米大屯7号地\", \"label\": \"不匹配\"}, {\"text\": \"中原路商隐路交汇处清华·大溪地七号院\", \"label\": \"不匹配\"}, {\"text\": \"滨海新区博美园7号楼\", \"label\": \"不匹配\"}, {\"text\": \"莲池区秀兰城市美地7号楼\", \"label\": \"不匹配\"}]}\r\n"
     ]
    }
   ],
   "source": [
    "!head dataset/Xeon3NLP_round1_train_20210524.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.paddlenlp库引入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paddlenlp库引入\r\n",
    "import paddlenlp as ppnlp\r\n",
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "from paddlenlp.datasets import load_dataset\r\n",
    "from paddlenlp.data import Stack, Tuple, Pad\r\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import json\r\n",
    "import time\r\n",
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddlenlp.datasets import load_dataset\r\n",
    "import paddlenlp\r\n",
    "\r\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.自定义reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = []\r\n",
    "dev_tmp = []\r\n",
    "num = 0 \r\n",
    "a = []\r\n",
    "for line in open('dataset/Xeon3NLP_round1_train_20210524.txt','r'):\r\n",
    "    t = json.loads(line)\r\n",
    "    for j in t['candidate']:\r\n",
    "        l = dict()\r\n",
    "        l['query'] = str(t['query'])\r\n",
    "        l['title'] = str(j['text'])\r\n",
    "        a.append(len(l['title']))\r\n",
    "        if j['label'] == '不匹配':\r\n",
    "            l['label'] = 0\r\n",
    "        elif j['label'] == '完全匹配':\r\n",
    "            l['label'] = 2\r\n",
    "        else:\r\n",
    "            l['label'] = 1\r\n",
    "        if num <18000:\r\n",
    "            train_tmp.append(l)\r\n",
    "        else:\r\n",
    "            dev_tmp.append(l)\r\n",
    "    num += 1\r\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\r\n",
    "def read(filename):\r\n",
    "    for line in filename:\r\n",
    "        yield {'query': line['query'], 'title': line['title'], 'label':line['label']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds = load_dataset(read, filename=train_tmp, lazy=False)\r\n",
    "dev_ds = load_dataset(read, filename=dev_tmp, lazy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '河南省巩义市新华路街道办事处桐和街6号钢苑新区3号楼一单元', 'title': '巩义市桐和街', 'label': 0}\n",
      "{'query': '河南省巩义市新华路街道办事处桐和街6号钢苑新区3号楼一单元', 'title': '桐和街依家小店', 'label': 0}\n",
      "{'query': '河南省巩义市新华路街道办事处桐和街6号钢苑新区3号楼一单元', 'title': '桐和街CHANG六LIULIU', 'label': 0}\n",
      "{'query': '河南省巩义市新华路街道办事处桐和街6号钢苑新区3号楼一单元', 'title': '桐和街佳乐钢琴', 'label': 0}\n",
      "{'query': '河南省巩义市新华路街道办事处桐和街6号钢苑新区3号楼一单元', 'title': '世博领秀城南门桐和街囍饭食堂', 'label': 0}\n",
      "{'query': '老垅坡高家组省建五公司', 'title': '高家巷省建五公司岳阳分公司', 'label': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-07 01:20:02,439] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/roberta-wwm-ext/roberta_chn_base.pdparams\n",
      "[2021-07-07 01:20:07,198] [    INFO] - Found /home/aistudio/.paddlenlp/models/roberta-wwm-ext/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "for idx, example in enumerate(train_ds):\r\n",
    "    if idx <= 5:\r\n",
    "        print(example)\r\n",
    "        \r\n",
    "def convert_example(example, tokenizer, max_seq_length=80, is_test=False):\r\n",
    "\r\n",
    "    query, title = example[\"query\"], example[\"title\"]\r\n",
    "\r\n",
    "    encoded_inputs = tokenizer(\r\n",
    "        text=query, text_pair=title, max_seq_len=max_seq_length)\r\n",
    "\r\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\r\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\r\n",
    "\r\n",
    "    if not is_test:\r\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\r\n",
    "        return input_ids, token_type_ids, label\r\n",
    "    # 在预测或者评估阶段，不返回 label 字段\r\n",
    "    else:\r\n",
    "        return input_ids, token_type_ids\r\n",
    "pretrained_model = paddlenlp.transformers.RobertaModel.from_pretrained('roberta-wwm-ext')\r\n",
    "\r\n",
    "tokenizer = paddlenlp.transformers.RobertaTokenizer.from_pretrained('roberta-wwm-ext')\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\r\n",
    "\r\n",
    "class PointwiseMatching(nn.Layer):\r\n",
    "   \r\n",
    "    # 此处的 pretained_model 在本例中会被 ERNIE1.0 预训练模型初始化\r\n",
    "    def __init__(self, pretrained_model, dropout=None):\r\n",
    "        super().__init__()\r\n",
    "        self.ptm = pretrained_model\r\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\r\n",
    "        self.classifier = nn.Linear(self.ptm.config[\"hidden_size\"], 3)\r\n",
    "\r\n",
    "    def forward(self,\r\n",
    "                input_ids,\r\n",
    "                token_type_ids=None,\r\n",
    "                position_ids=None,\r\n",
    "                attention_mask=None):\r\n",
    "\r\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids, position_ids,\r\n",
    "                                    attention_mask)\r\n",
    "        cls_embedding = self.dropout(cls_embedding)\r\n",
    "        logits = self.classifier(cls_embedding)\r\n",
    "\r\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = PointwiseMatching(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.定义样本转换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将 1 条明文数据的 query、title 拼接起来，根据预训练模型的 tokenizer 将明文转换为 ID 数据\r\n",
    "# 返回 input_ids 和 token_type_ids\r\n",
    "\r\n",
    "def convert_example(example, tokenizer, max_seq_length=80, is_test=False):\r\n",
    "\r\n",
    "    query, title = example[\"query\"], example[\"title\"]\r\n",
    "\r\n",
    "    encoded_inputs = tokenizer(\r\n",
    "        text=query, text_pair=title, max_seq_len=max_seq_length)\r\n",
    "\r\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\r\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\r\n",
    "\r\n",
    "    if not is_test:\r\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\r\n",
    "        return input_ids, token_type_ids, label\r\n",
    "    # 在预测或者评估阶段，不返回 label 字段\r\n",
    "    else:\r\n",
    "        return input_ids, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 为了后续方便使用，我们给 convert_example 赋予一些默认参数\r\n",
    "from functools import partial\r\n",
    "\r\n",
    "# 训练集和验证集的样本转换函数\r\n",
    "trans_func = partial(\r\n",
    "    convert_example,\r\n",
    "    tokenizer=tokenizer,\r\n",
    "    max_seq_length=80)\r\n",
    "    # 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 组装 Batch 数据 & Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "from paddlenlp.data import Stack, Pad, Tuple\r\n",
    "# 我们的训练数据会返回 input_ids, token_type_ids, labels 3 个字段\r\n",
    "# 因此针对这 3 个字段需要分别定义 3 个组 batch 操作\r\n",
    "batchify_fn = lambda samples, fn=Tuple(\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\r\n",
    "    Stack(dtype=\"int64\")  # label\r\n",
    "): [data for data in fn(samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.定义 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 基于 train_ds 定义 train_data_loader\r\n",
    "# 因为我们使用了分布式的 DistributedBatchSampler, train_data_loader 会自动对训练数据进行切分\r\n",
    "# 定义分布式 Sampler: 自动对训练数据进行切分，支持多卡并行训练\r\n",
    "batch_sampler = paddle.io.DistributedBatchSampler(train_ds, batch_size=400, shuffle=True)\r\n",
    "train_data_loader = paddle.io.DataLoader(\r\n",
    "        dataset=train_ds.map(trans_func),\r\n",
    "        batch_sampler=batch_sampler,\r\n",
    "        collate_fn=batchify_fn,\r\n",
    "        return_list=True)\r\n",
    "\r\n",
    "# 针对验证集数据加载，我们使用单卡进行评估，所以采用 paddle.io.BatchSampler 即可\r\n",
    "# 定义 dev_data_loader\r\n",
    "batch_sampler = paddle.io.BatchSampler(dev_ds, batch_size=400, shuffle=False)\r\n",
    "dev_data_loader = paddle.io.DataLoader(\r\n",
    "        dataset=dev_ds.map(trans_func),\r\n",
    "        batch_sampler=batch_sampler,\r\n",
    "        collate_fn=batchify_fn,\r\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\r\n",
    "# 训练过程中的最大学习率\r\n",
    "learning_rate = 2e-5 \r\n",
    "# 训练轮次\r\n",
    "epochs = 100\r\n",
    "# 学习率预热比例\r\n",
    "warmup_proportion = 0.1\r\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\r\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_training_steps = len(train_data_loader) * epochs\r\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\r\n",
    "optimizer = paddle.optimizer.AdamW(\r\n",
    "    learning_rate=lr_scheduler,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    weight_decay=weight_decay,\r\n",
    "    apply_decay_param_fun=lambda x: x in [\r\n",
    "        p.name for n, p in model.named_parameters()\r\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "    ])\r\n",
    "\r\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\r\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\r\n",
    "\r\n",
    "num_training_steps = len(train_data_loader) * epochs\r\n",
    "\r\n",
    "# 定义 learning_rate_scheduler，负责在训练过程中对 lr 进行调度\r\n",
    "lr_scheduler = LinearDecayWithWarmup(5E-5, num_training_steps, 0.0)\r\n",
    "\r\n",
    "# Generate parameter names needed to perform weight decay.\r\n",
    "# All bias and LayerNorm parameters are excluded.\r\n",
    "decay_params = [\r\n",
    "    p.name for n, p in model.named_parameters()\r\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "]\r\n",
    "\r\n",
    "# 定义 Optimizer\r\n",
    "optimizer = paddle.optimizer.AdamW(\r\n",
    "    learning_rate=lr_scheduler,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    weight_decay=0.0,\r\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\r\n",
    "\r\n",
    "# 采用交叉熵 损失函数\r\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\r\n",
    "\r\n",
    "# 评估的时候采用准确率指标\r\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 加入日志显示\r\n",
    "from visualdl import LogWriter\r\n",
    "\r\n",
    "writer = LogWriter(\"./log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 因为训练过程中同时要在验证集进行模型评估，因此我们先定义评估函数\r\n",
    "\r\n",
    "@paddle.no_grad()\r\n",
    "def evaluate(model, criterion, metric, data_loader, phase=\"dev\"):\r\n",
    "    model.eval()\r\n",
    "    metric.reset()\r\n",
    "    losses = []\r\n",
    "    for batch in data_loader:\r\n",
    "        input_ids, token_type_ids, labels = batch\r\n",
    "        probs = model(input_ids=input_ids, token_type_ids=token_type_ids)\r\n",
    "        loss = criterion(probs, labels)\r\n",
    "        losses.append(loss.numpy())\r\n",
    "        correct = metric.compute(probs, labels)\r\n",
    "        metric.update(correct)\r\n",
    "        accu = metric.accumulate()\r\n",
    "    print(\"eval {} loss: {:.5}, accu: {:.5}\".format(phase,\r\n",
    "                                                    np.mean(losses), accu))\r\n",
    "    \r\n",
    "    # 加入eval日志显示\r\n",
    "    writer.add_scalar(tag=\"eval/loss\", step=global_step, value=np.mean(losses))\r\n",
    "    writer.add_scalar(tag=\"eval/acc\", step=global_step, value=accu)                                                  \r\n",
    "    model.train()\r\n",
    "    metric.reset()\r\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 15580, epoch: 72, batch: 173, loss: 0.00863, accu: 0.99809, speed: 0.65 step/s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1b431880b46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ec17a4daab3b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         _, cls_embedding = self.ptm(input_ids, token_type_ids, position_ids,\n\u001b[0;32m---> 19\u001b[0;31m                                     attention_mask)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcls_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/roberta/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             attention_mask = paddle.unsqueeze(\n\u001b[0;32m--> 334\u001b[0;31m                 (input_ids == self.pad_token_id\n\u001b[0m\u001b[1;32m    335\u001b[0m                  ).astype(self.pooler.dense.weight.dtype) * -1e9,\n\u001b[1;32m    336\u001b[0m                 axis=[1, 2])\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(self, other_var)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mmath_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmath_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpProtoHolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_op_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 接下来，开始正式训练模型\r\n",
    "save_dir = \"checkpoint\"\r\n",
    "os.makedirs(save_dir)\r\n",
    "global_step = 0\r\n",
    "tic_train = time.time()\r\n",
    "pre_accu=0\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\r\n",
    "\r\n",
    "        input_ids, token_type_ids, labels = batch\r\n",
    "        probs = model(input_ids=input_ids, token_type_ids=token_type_ids)\r\n",
    "        loss = criterion(probs, labels)\r\n",
    "        correct = metric.compute(probs, labels)\r\n",
    "        metric.update(correct)\r\n",
    "        acc = metric.accumulate()\r\n",
    "\r\n",
    "        global_step += 1\r\n",
    "        \r\n",
    "        # 每间隔 10 step 输出训练指标\r\n",
    "        if global_step % 10 == 0:\r\n",
    "            print(\r\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\r\n",
    "                % (global_step, epoch, step, loss, acc,\r\n",
    "                    10 / (time.time() - tic_train)))\r\n",
    "            tic_train = time.time()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        lr_scheduler.step()\r\n",
    "        optimizer.clear_grad()\r\n",
    "\r\n",
    "\r\n",
    "        # 每间隔 100 step 在验证集和测试集上进行评估\r\n",
    "        if global_step % 100 == 0:\r\n",
    "            accu=evaluate(model, criterion, metric, dev_data_loader, \"dev\")\r\n",
    "        \r\n",
    "        # 加入train日志显示\r\n",
    "            writer.add_scalar(tag=\"train/loss\", step=global_step, value=loss)\r\n",
    "            writer.add_scalar(tag=\"train/acc\", step=global_step, value=acc)\r\n",
    "            \r\n",
    "            if accu>pre_accu:\r\n",
    "                # 加入保存\r\n",
    "                save_param_path = os.path.join(save_dir, 'model_state.pdparams')\r\n",
    "                paddle.save(model.state_dict(), save_param_path)\r\n",
    "                # tokenizer.save_pretrained(save_dir)\r\n",
    "                pre_accu=accu\r\n",
    "            \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练日志截取\n",
    "```\n",
    "global step 510, epoch: 3, batch: 76, loss: 0.31065, accu: 0.87175, speed: 0.34 step/s\n",
    "global step 520, epoch: 3, batch: 86, loss: 0.36163, accu: 0.87113, speed: 0.64 step/s\n",
    "global step 530, epoch: 3, batch: 96, loss: 0.27322, accu: 0.87517, speed: 0.64 step/s\n",
    "global step 540, epoch: 3, batch: 106, loss: 0.38036, accu: 0.87538, speed: 0.65 step/s\n",
    "global step 550, epoch: 3, batch: 116, loss: 0.30168, accu: 0.87545, speed: 0.66 step/s\n",
    "global step 560, epoch: 3, batch: 126, loss: 0.34728, accu: 0.87667, speed: 0.66 step/s\n",
    "global step 570, epoch: 3, batch: 136, loss: 0.28104, accu: 0.87754, speed: 0.65 step/s\n",
    "global step 580, epoch: 3, batch: 146, loss: 0.30536, accu: 0.87803, speed: 0.68 step/s\n",
    "global step 590, epoch: 3, batch: 156, loss: 0.35877, accu: 0.87739, speed: 0.65 step/s\n",
    "global step 600, epoch: 3, batch: 166, loss: 0.39249, accu: 0.87828, speed: 0.65 step/s\n",
    "eval dev loss: 0.47208, accu: 0.83651\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6.模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练结束后，存储模型参数\r\n",
    "save_dir = os.path.join(\"checkpoint2\", \"model_%d\" % global_step)\r\n",
    "os.makedirs(save_dir)\r\n",
    "\r\n",
    "save_param_path = os.path.join(save_dir, 'model_state111.pdparams')\r\n",
    "paddle.save(model.state_dict(), save_param_path)\r\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.载入模型\n",
    "* 训练完毕后先重启释放缓存\n",
    "* 再运行上面训练前的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dict=paddle.load('checkpoint/model_state.pdparams')\r\n",
    "model.set_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchify_test_fn = lambda samples, fn=Tuple(\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\r\n",
    "): [data for data in fn(samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  2.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "****************************************\n",
      "num: f15000\n"
     ]
    }
   ],
   "source": [
    "num = 0\r\n",
    "fo = open(\"submit_addr_match_runid4.txt\", \"w\")\r\n",
    "for line in open('dataset/Xeon3NLP_round1_test_20210524.txt','r', encoding='utf8'):\r\n",
    "    t = json.loads(line)\r\n",
    "    for j in range(len(t['candidate'])):\r\n",
    "        tmp = []\r\n",
    "        l = dict()\r\n",
    "        l['query'] = t['query']\r\n",
    "        l['title'] = t['candidate'][j]['text']\r\n",
    "        l['label'] = 0\r\n",
    "        input_ids, token_type_ids,label = convert_example(l, tokenizer, max_seq_length=80)\r\n",
    "        tmp.append((input_ids, token_type_ids))\r\n",
    "        input_ids, token_type_ids = batchify_test_fn(tmp)\r\n",
    "        input_ids = paddle.to_tensor(input_ids)\r\n",
    "        token_type_ids = paddle.to_tensor(token_type_ids)\r\n",
    "        logits = model(input_ids, token_type_ids)\r\n",
    "        idx = paddle.argmax(logits, axis=1).numpy()\r\n",
    "        if idx[0] == 0:\r\n",
    "            t['candidate'][j]['label'] = '不匹配'\r\n",
    "        elif idx[0] == 1:\r\n",
    "            t['candidate'][j]['label'] = '部分匹配'\r\n",
    "        else:\r\n",
    "            t['candidate'][j]['label'] = '完全匹配'\r\n",
    "    # if num < 10:\r\n",
    "    #     print(t)\r\n",
    "    # print(t['candidate'][j]['label'] )\r\n",
    "    if num % 500 == 0:\r\n",
    "        print(num)\r\n",
    "    fo.write(json.dumps(t,ensure_ascii=False))\r\n",
    "    fo.write('\\n')\r\n",
    "    num +=1\r\n",
    "print(40*'*')\r\n",
    "print(f\"num: f{num}\")\r\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.格式检查并提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\r\n",
    "import linecache\r\n",
    "\r\n",
    "\r\n",
    "def check(submit_path, test_path, max_num=15000):\r\n",
    "    '''\r\n",
    "    :param submit_path: 选手提交的文件名\r\n",
    "    :param test_path: 原始测试数据名\r\n",
    "    :param max_num: 测试数据大小\r\n",
    "    :return:\r\n",
    "    '''\r\n",
    "    N = 0\r\n",
    "    with open(submit_path, 'r', encoding='utf-8') as fs:\r\n",
    "        for line in fs:\r\n",
    "            try:\r\n",
    "                line = line.strip()\r\n",
    "                if line == '':\r\n",
    "                    continue\r\n",
    "                N += 1\r\n",
    "                smt_jsl = json.loads(line)\r\n",
    "                test_jsl = json.loads(linecache.getline(test_path, N))\r\n",
    "                if set(smt_jsl.keys()) != {'text_id', 'query', 'candidate'}:\r\n",
    "                    raise AssertionError(f'请保证提交的JSON数据的所有key与测评数据一致！ {line}')\r\n",
    "                elif smt_jsl['text_id'] != test_jsl['text_id']:\r\n",
    "                    raise AssertionError(f'请保证text_id和测评数据一致，并且不要改变数据顺序！text_id: {smt_jsl[\"text_id\"]}')\r\n",
    "                elif smt_jsl['query'] != test_jsl['query']:\r\n",
    "                    raise AssertionError(f'请保证query内容和测评数据一致！text_id: {smt_jsl[\"text_id\"]}, query: {smt_jsl[\"query\"]}')\r\n",
    "                elif len(smt_jsl['candidate']) != len(test_jsl['candidate']):\r\n",
    "                    raise AssertionError(f'请保证candidate的数量和测评数据一致！text_id: {smt_jsl[\"text_id\"]}')\r\n",
    "                else:\r\n",
    "                    for smt_cand, test_cand in zip(smt_jsl['candidate'], test_jsl['candidate']):\r\n",
    "                        if smt_cand['text'] != test_cand['text']:\r\n",
    "                            raise AssertionError(f'请保证candidate的内容和顺序与测评数据一致！text_id: {smt_jsl[\"text_id\"]}, candidate_item: {smt_cand[\"text\"]}')\r\n",
    "\r\n",
    "            except json.decoder.JSONDecodeError:\r\n",
    "                raise AssertionError(f'请检查提交数据的JSON格式是否有误！如：用键-值用双引号 {line}')\r\n",
    "            except KeyError:\r\n",
    "                raise AssertionError(f'请保证提交的JSON数据的所有key与测评数据一致！{line}')\r\n",
    "\r\n",
    "    if N != max_num:\r\n",
    "        raise AssertionError(f\"请保证测试数据的完整性(共{max_num}条)，不可丢失或增加数据！\")\r\n",
    "\r\n",
    "    print('Well Done ！！')\r\n",
    "\r\n",
    "check('submit_addr_match_runid4.txt', 'dataset/Xeon3NLP_round1_test_20210524.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五、成绩\n",
    "大概2个epoch，成绩约为0.76，希望大家可以取得更好的成绩。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5b990780570e46bd8b142bd28c97ad76c610433ce23749c497f76ec2428d5220)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
